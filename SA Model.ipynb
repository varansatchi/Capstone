{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - Positive / Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import json\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, GlobalMaxPool1D, Dropout, concatenate\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3018: DtypeWarning: Columns (0,15,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3018: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3018: DtypeWarning: Columns (10,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# loading in the 13 CSVs\n",
    "df1 = pd.read_csv('./russian-troll-tweets/IRAhandle_tweets_1.csv')\n",
    "df2 = pd.read_csv('./russian-troll-tweets/IRAhandle_tweets_2.csv')\n",
    "df3 = pd.read_csv('./russian-troll-tweets/IRAhandle_tweets_3.csv')\n",
    "df4 = pd.read_csv('./russian-troll-tweets/IRAhandle_tweets_4.csv')\n",
    "df5 = pd.read_csv('./russian-troll-tweets/IRAhandle_tweets_5.csv')\n",
    "df6 = pd.read_csv('./russian-troll-tweets/IRAhandle_tweets_6.csv')\n",
    "df7 = pd.read_csv('./russian-troll-tweets/IRAhandle_tweets_7.csv')\n",
    "df8 = pd.read_csv('./russian-troll-tweets/IRAhandle_tweets_8.csv')\n",
    "df9 = pd.read_csv('./russian-troll-tweets/IRAhandle_tweets_9.csv')\n",
    "df10 = pd.read_csv('./russian-troll-tweets/IRAhandle_tweets_10.csv')\n",
    "df11 = pd.read_csv('./russian-troll-tweets/IRAhandle_tweets_11.csv')\n",
    "df12 = pd.read_csv('./russian-troll-tweets/IRAhandle_tweets_12.csv')\n",
    "df13 = pd.read_csv('./russian-troll-tweets/IRAhandle_tweets_13.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to combine these dataframes together for ease of use\n",
    "frames = [df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with non-English tweets, while interesting, is beyond my linguistic capabilities!\n",
    "mask = master['language'] == 'English'\n",
    "eng = master[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Postive / Negative Sentiment NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# extract data from a csv\n",
    "# notice the cool options to skip lines at the beginning\n",
    "# and to only take data from certain columns\n",
    "training = np.genfromtxt('./Sentiment Analysis Dataset.csv', delimiter=',', skip_header=1, usecols=(1, 3), dtype=None)\n",
    "\n",
    "# create our training data from the tweets\n",
    "train_x = [x[1] for x in training]\n",
    "# index all the sentiment labels\n",
    "train_y = np.asarray([x[0] for x in training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only work with the 3000 most popular words found in our dataset\n",
    "max_words = 3000\n",
    "\n",
    "# create a new Tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "# feed our tweets to the Tokenizer\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "# Tokenizers come with a convenient list of words and IDs\n",
    "dictionary = tokenizer.word_index\n",
    "# Let's save this out so we can use it later\n",
    "with open('dictionary.json', 'w') as dictionary_file:\n",
    "    json.dump(dictionary, dictionary_file)\n",
    "\n",
    "\n",
    "def convert_text_to_index_array(text):\n",
    "    # one really important thing that `text_to_word_sequence` does\n",
    "    # is make all texts the same length -- in this case, the length\n",
    "    # of the longest text in the set.\n",
    "    return [dictionary[word] for word in kpt.text_to_word_sequence(text)]\n",
    "\n",
    "allWordIndices = []\n",
    "# for each tweet, change each token to its ID in the Tokenizer's word_index\n",
    "for text in train_x:\n",
    "    wordIndices = convert_text_to_index_array(text)\n",
    "    allWordIndices.append(wordIndices)\n",
    "\n",
    "# now we have a list of all tweets converted to index arrays.\n",
    "# cast as an array for future usage.\n",
    "allWordIndices = np.asarray(allWordIndices)\n",
    "\n",
    "# create one-hot matrices out of the indexed tweets\n",
    "train_x = tokenizer.sequences_to_matrix(allWordIndices, mode='binary')\n",
    "# treat the labels as categories\n",
    "train_y = keras.utils.to_categorical(train_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1420764 samples, validate on 157863 samples\n",
      "Epoch 1/5\n",
      "1420764/1420764 [==============================] - 1333s 938us/step - loss: 0.4949 - acc: 0.7609 - val_loss: 0.4493 - val_acc: 0.7891\n",
      "Epoch 2/5\n",
      "1420764/1420764 [==============================] - 985s 693us/step - loss: 0.4739 - acc: 0.7761 - val_loss: 0.4441 - val_acc: 0.7926\n",
      "Epoch 3/5\n",
      "1420764/1420764 [==============================] - 1059s 746us/step - loss: 0.4659 - acc: 0.7821 - val_loss: 0.4449 - val_acc: 0.7917\n",
      "Epoch 4/5\n",
      "1420764/1420764 [==============================] - 1124s 791us/step - loss: 0.4608 - acc: 0.7861 - val_loss: 0.4491 - val_acc: 0.7918\n",
      "Epoch 5/5\n",
      "1420764/1420764 [==============================] - 1050s 739us/step - loss: 0.4567 - acc: 0.7886 - val_loss: 0.4441 - val_acc: 0.7927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b4c09588>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# commenting out, so I don't accidently run!\n",
    "# model.fit(train_x, train_y, batch_size=32, epochs=5,verbose=1, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in Troll Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_cat_ddf = eng[['content', 'account_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395496 tweets loaded\n",
      "CPU times: user 644 ms, sys: 77.3 ms, total: 721 ms\n",
      "Wall time: 781 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "content_cat_df = content_cat_ddf.sample(frac=0.2).drop_duplicates()\n",
    "print(content_cat_df.shape[0], 'tweets loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running IRA Tweets through Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "maxlen=3000\n",
    "list_tweets = content_cat_df[\"content\"].fillna(\"Invalid\").values\n",
    "list_tokenized_tweets = tokenizer.texts_to_sequences(list_tweets)\n",
    "X_twe = sequence.pad_sequences(list_tokenized_tweets, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395496/395496 [==============================] - 32s 80us/step\n",
      "CPU times: user 1min 1s, sys: 5.86 s, total: 1min 7s\n",
      "Wall time: 31.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_twe = model.predict(X_twe, batch_size=1024, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['positive', 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Input Sentence:\n",
       " `#MyOlympicSportWouldBe the 3-legged race because I'm, well... shall I say gifted`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Scores"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- positive, Prediction: 44.55%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- negative, Prediction: 55.45%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display_markdown = lambda x: display(Markdown(x))\n",
    "def show_sentence(sent_idx):\n",
    "    display_markdown('# Input Sentence:\\n `{}`'.format(list_tweets[sent_idx]))\n",
    "    c_pred = model.predict(X_twe[sent_idx:sent_idx+1])[0]\n",
    "    display_markdown('## Scores')\n",
    "    for k, p in zip(labels, c_pred):\n",
    "        display_markdown('- {}, Prediction: {:2.2f}%'.format(k, 100*p))\n",
    "show_sentence(np.random.randint(0,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_df = pd.DataFrame(y_twe, columns = labels)\n",
    "senti_df['content_category'] = content_cat_df['account_category'].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>content_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>282900</th>\n",
       "      <td>0.509092</td>\n",
       "      <td>0.490908</td>\n",
       "      <td>RightTroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139275</th>\n",
       "      <td>0.466040</td>\n",
       "      <td>0.533960</td>\n",
       "      <td>NewsFeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6540</th>\n",
       "      <td>0.481034</td>\n",
       "      <td>0.518966</td>\n",
       "      <td>Commercial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385136</th>\n",
       "      <td>0.445500</td>\n",
       "      <td>0.554500</td>\n",
       "      <td>NewsFeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191505</th>\n",
       "      <td>0.408626</td>\n",
       "      <td>0.591374</td>\n",
       "      <td>RightTroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        negative  positive content_category\n",
       "282900  0.509092  0.490908       RightTroll\n",
       "139275  0.466040  0.533960         NewsFeed\n",
       "6540    0.481034  0.518966       Commercial\n",
       "385136  0.445500  0.554500         NewsFeed\n",
       "191505  0.408626  0.591374       RightTroll"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Input Sentence:\n",
       " `RT entjboss: I really want to believe in Mitch, but I can't tolerate excuses. We have the capability to have a HUGâ€¦ https://t.co/DFy5N0LPj4`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Scores"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- positive, Prediction: 82.77%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- negative, Prediction: 17.23%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Input Sentence:\n",
       " `RT ShaunLeaneMP: There can be no doubt now the Victorian Liberals have put in a heap of time and effort to secure the gangster vote â€¦`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Scores"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- positive, Prediction: 80.52%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- negative, Prediction: 19.48%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Input Sentence:\n",
       " `RT GeorgiaDirtRoad: The swamp is very thick in D.C. and you do have those lingering people who don't want to see POTUS succeed. ðŸŽ¯ðŸŽ¯ðŸŽ¯https://â€¦`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Scores"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- positive, Prediction: 79.09%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- negative, Prediction: 20.91%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Input Sentence:\n",
       " `.@Reince: \"The voters spoke, and they elected Republicans in the White House, the Senate, the House, and they did it with great fervor.\" https://t.co/K2q2TVImY7`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Scores"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- positive, Prediction: 78.84%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- negative, Prediction: 21.16%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Input Sentence:\n",
       " `RT CollinRugg: Wasserman Shultz, Imran Awan &amp; a Senator saying \"I Hope Trump Is Assassinated\"  Not a good day to be a Dem. Way to keep it câ€¦`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Scores"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- positive, Prediction: 78.58%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- negative, Prediction: 21.42%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "worst_tweets = np.argsort(senti_df['negative'].values)\n",
    "for _, idx in zip(range(5), \n",
    "                  worst_tweets):\n",
    "    show_sentence(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Input Sentence:\n",
       " `My wife is a social butterfly.  Me ?   I'm in the cocoon stage... waiting for my metamorphosis.  Just a hunch, but it may never come.`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Scores"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- positive, Prediction: 3.28%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- negative, Prediction: 96.72%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Input Sentence:\n",
       " `#top RT KORANISBURNING: I see is Trump is setting up a chest board, if a #2ndSpecialCounsel is appointed This is about to get very messy reâ€¦`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Scores"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- positive, Prediction: 5.76%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- negative, Prediction: 94.24%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Input Sentence:\n",
       " `'@Nettaaaaaaaa \"of course I/we support, I/we just don't think this is the right time...\"  #shitimtiredof'`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Scores"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- positive, Prediction: 6.16%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- negative, Prediction: 93.84%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Input Sentence:\n",
       " `RT ChChanJu76: steph93065 How about just get rid of Obamacare so that insurance companies don't have to be bailed out? Oh wait...`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Scores"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- positive, Prediction: 6.24%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- negative, Prediction: 93.76%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Input Sentence:\n",
       " `Trump gives an interview to some Christian group revealing the intent of the ban is to help christians. That's not very Christian, right?`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Scores"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- positive, Prediction: 6.91%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- negative, Prediction: 93.09%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_tweets = np.argsort(senti_df['positive'].values)\n",
    "for _, idx in zip(range(5), \n",
    "                  best_tweets):\n",
    "    show_sentence(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
